{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c5d99f-ca0f-49d6-b98a-0b263d586a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7088ad27-3b87-4515-9d36-45b813fc3eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput s3 path: s3://notebookllama-project/async-llm-output/output\n",
      "role arn:aws:iam::867521064370:role/sagemaker\n",
      "us-east-1\n",
      "notebookllama-project\n",
      "<botocore.client.SageMakerRuntime object at 0x7f91b917ce50>\n",
      "1368\n"
     ]
    }
   ],
   "source": [
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = session._region_name\n",
    "client = boto3.client(\"sagemaker-runtime\")\n",
    "session_bucket = 'notebookllama-project'\n",
    "bucket_prefix = \"async-llm-output\"\n",
    "async_output_path = f\"s3://{session_bucket}/{bucket_prefix}/output\"\n",
    "\n",
    "time_str = str(time.time())[-4:]\n",
    "print('ouput s3 path:', async_output_path)\n",
    "print('role', role)\n",
    "print(region)\n",
    "print(session_bucket)\n",
    "print(client)\n",
    "print(time_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5bc818-f729-4286-8021-3e6e1cdbd06a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy Llama models via jumpstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de380c31-db9e-4ab5-814f-0f665c98ec9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=async_output_path,\n",
    "    max_concurrent_invocations_per_instance=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76473419-fc77-495c-a0a2-eca9f2637ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-3-2-1b-instruct' with wildcard version identifier '*'. You can pin to version '1.0.4' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-3-1-8b-instruct' with wildcard version identifier '*'. You can pin to version '2.2.4' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-3-1-70b-instruct' with wildcard version identifier '*'. You can pin to version '2.2.5' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model_id_list =[ \"meta-textgeneration-llama-3-2-1b-instruct\",  \"meta-textgeneration-llama-3-1-8b-instruct\"\n",
    ", \"meta-textgeneration-llama-3-1-70b-instruct\"]\n",
    "instance_type_list = ['ml.g5.12xlarge','ml.g5.24xlarge', 'ml.g5.48xlarge'] \n",
    "\n",
    "for index, model_id in enumerate(model_id_list):\n",
    "    model = JumpStartModel(model_id=model_id)\n",
    "    predictor = model.deploy(\n",
    "        # async_inference_config=async_config,\n",
    "        instance_type = instance_type_list[index],\n",
    "        endpoint_name= model_id+'-endpoint-'+time_str,\n",
    "        accept_eula=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbab11-f463-4da1-86a8-f800232817f2",
   "metadata": {},
   "source": [
    "## Deploy Qwen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a486bbc-acc2-4dbf-bb99-c1c53f99fed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------!"
     ]
    }
   ],
   "source": [
    "container_uri = sagemaker.image_uris.retrieve(framework=\"djl-lmi\", version=\"0.28.0\", region=region)\n",
    "model_id = 'Qwen/Qwen2-72B-Instruct'\n",
    "endpoint_name = 'Qwen2-72B-Instruct-endpoint-'+time_str\n",
    "instance_type ='ml.g5.48xlarge'\n",
    "\n",
    "model = sagemaker.Model(\n",
    "    image_uri=container_uri, \n",
    "    role=role,\n",
    "    env={\n",
    "        \"HF_MODEL_ID\": model_id,\n",
    "        \"OPTION_DTYPE\":\"fp16\",\n",
    "    }\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    # async_inference_config=async_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80701f78-46a3-4e79-b8d5-600fa1ba2b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
